# Project 1:Urban Data Cleaning, Integration, and Enrichment with Python

**Course:** CS 4/5630, PYTHON FOR COMPUTATIONAL AND DATA SCIENCES  
**Instructor:** Dr. Arijit Khan  
**Group 1** Quang Minh Nguyen, Rachel Stevenson, Jack Handley, Isaac Avila, Vaughn Gugger, Chaz Wilms

## Project Overview
This project features a complete Python pipeline that integrates structured data from NYC Philadelphia 311 Service Requests and unstructured text data from the Yelp Open Dataset. The final output is a cleaned, enriched, and integrated dataset supporting the analysis of urban service complaints in relation to local business environments. 

## Datasets
1. **Philadelphia 311 Service Requests:** Contains complaint types, descriptions, timestamps, and locations.
2. **Yelp Open Dataset:** Contains business metadata, categories, geolocation, and review text.

## Repository Structure
* `data/raw/`: Directory for the original, downloaded datasets. *(Note: Data files are ignored via .gitignore due to size)*
* `data/processed/`: Directory for the cleaned and integrated final datasets. *(Note: Data files are ignored via .gitignore)*
* `src/`: Directory containing all Python scripts and Jupyter Notebooks for the data pipeline.
* `Project-1_Report.pdf`: The final 10-page project report detailing problems studied, solutions proposed, and key findings.

## How to Run the Code
1. Ensure you have Python installed, along with the required libraries:
2. **Data Access:** To get the exact raw data we used, please contact Chaz to receive the dataset ZIP files, as the open source data sets are continuouslly updating, the specific datasets we used are hosted in a shared team OneDrive folder. Once received, extract the CSV and JSON files directly into the `data/raw/` folder.
3. Run the data cleaning pipeline by executing: 
4. Run the data integration script by executing: 

## How to Comprehend the Outputs
---